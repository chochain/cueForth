#+title: tensorForth
#+subtitle: Forth lives in GPU
#+OPTIONS: toc:nil num:nil html-postamble:nil ^:{} reveal_title_slide:nil
#+REVEAL_ROOT: https://cdn.jsdelivr.net/npm/reveal.js
#+REVEAL_THEME: night
#+REVEAL_HLEVEL: 2
#+REVEAL_EXTRA_CSS: ./org-example.css
#+REVEAL_INIT_OPTIONS: slideNumber:"c/t", transition:"none", transitionSpeed:"fast", controlsTutorial:false, minScale:1.0, maxScale:1.5
#+REVEAL_EXTRA_SCRIPT: for(let e of document.getElementsByClassName("figure-number")){e.parentElement.classList.add("fig-caption");}
#+REVEAL_TITLE_SLIDE: <h2 class="title">%t</h2><em>%s</em><br><br>%a<br>%d<br>
#+REVEAL_PLUGINS: highlight notes

* Artifitial Intelligence
#+ATTR_REVEAL: :frag roll-in
+ Neaural Network (not Expert System)
  - Many layers, thus called "Deep" Learning
+ Image/Video Processing
  - CNN (Convolutional Neaural Network)
  - think of it as eyes
+ Natual Language Processing
  - RNN (Recurrent NN)
  - Transformers (does better than RNN)
  - think of it as hearing & speach
#+BEGIN_NOTES
this is only a tests
#+END_NOTES
* Tensors
#+ATTR_REVEAL: :frag roll-in
+ Multilinear map between vector space
+ Treated as multi-dimeisonal arrays of numbers
+ Generalized with rank
  - Scalar - rank 0
  - Vector - rank 1
  - Matrix - rank 2
  - Higher order - rank 3, 4, ...
+ Can embed reference vectors (on this later)
* GPU to AI frenzy
#+ATTR_REVEAL: :frag grow
+ Massive parallelism
+ High thoughput
+ Local Memory
+ Fast math
+ Tensor Cores for matrix ops
** What is GPU anyway
#+ATTR_REVEAL: :frag roll-in
+ Graphics Processing Unit
  - A specialized processor
  - Many parallel cores
  - Did graphics & games only
+ Becomes General Purpose
  - Talk to CPU via PCIe
  - Good for scientific computing
  - Machine learning, of course
  - nVidia 98%, AMD 1%, Intel < 1%
** Programing nVidia GPU
#+ATTR_REVEAL: :frag roll-in
+ CUDA - C/C++ API
  - A gcc/LLVM variant
  - Translate C++ to PTX (portable code)
  - Assemble PTX to SASS (device dependent)
+ Python - dominant language for AI
  - PyCUDA - transcoder to C/C++
  - NumPy - an optimized array library
+ High level frameworks
  - PyTorch, TensorFlow, ...
  - Backend utilize CUDA libraries
  - Encapsulate CUDA calls
* Forth in GPU?
#+ATTR_REVEAL: :frag roll-in
+ Similar to a DSP (or MCU)
+ Use float data types
+ Need Data Structures
+ Handle memory allocation
+ Handle data transfer
+ Handle IO
+ Think in parallel
* Forth in GPU? - cont'
#+ATTR_REVEAL: :frag roll-in
+ Compile/Run vs Interpret
+ In assembly, C++, or Forth
+ On host or device
+ Memory types and transfer
+ Threading - SIMT, divergence
+ Streaming - workload balancing
* tensorForth
#+ATTR_REVEAL: :frag roll-in
+ = tensor + Forth
+ CUDA + C/C++-based Forth
  - Dictionary in device
  - Host input to device
  - Device output to host
+ Linear Algebra words
+ Machine Learning words
* Forth Code Example
* Thank you!
#+ATTR_REVEAL: :frag grow
+ More to come
[[https://raw.githubusercontent.com/chochain/tensorForth/master/docs/img/ten4_l7_loss.png]]


