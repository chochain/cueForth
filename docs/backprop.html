<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML">
</script>
<table>
<tr><td align=left>
$$
\mathbf{\frac{\partial y}{\partial x}} =
\begin{bmatrix}
\nabla f_1(\mathbf{x}) \\[1ex]
\nabla f_2(\mathbf{x}) \\[1ex]
... \\[1ex]
\nabla f_m(\mathbf{x})
\end{bmatrix} =
\begin{bmatrix}
\frac{\partial}{\partial \mathbf{x}}f_1(\mathbf{x}) \\[1ex]
\frac{\partial}{\partial \mathbf{x}}f_2(\mathbf{x}) \\[1ex]
... \\[1ex]
\frac{\partial}{\partial \mathbf{x}}f_m(\mathbf{x})
\end{bmatrix} = \begin{bmatrix}
\frac{\partial}{\partial x_1}f_1(\mathbf{x}) &
\frac{\partial}{\partial x_2}f_1(\mathbf{x}) &
... &
\frac{\partial}{\partial x_n}f_1(\mathbf{x}) \\[1ex]
\frac{\partial}{\partial x_1}f_2(\mathbf{x}) &
\frac{\partial}{\partial x_2}f_2(\mathbf{x}) &
... &
\frac{\partial}{\partial x_n}f_2(\mathbf{x}) \\[1ex]
& ... & \\[1ex]
\frac{\partial}{\partial x_1}f_m(\mathbf{x}) &
\frac{\partial}{\partial x_2}f_m(\mathbf{x}) &
... &
\frac{\partial}{\partial x_n}f_m(\mathbf{x})
\end{bmatrix}
$$
</td><tr>
<tr><td align=left>
$$
\begin{cases}
& u(\mathbf{w},\mathbf{x},b) & = max(0, \mathbf{w} \cdot \mathbf{x} + b) \\
& v(y, u) & = y - u \\
& C(v) = MSE(v) & = \frac{1}{N}\sum_{i=1}^N v^2 & derivatives =
\begin{cases}
& e_i & = \mathbf{w} \cdot \mathbf{x_i} + b - y_i \\
& \frac{\partial C}{\partial W} & = \frac{2}{N}\sum\limits_{i=1}^N e_i\mathbf{x}_i^T & \text{ for non-zero activation cases } \\
& \frac{\partial C}{\partial B} & = \frac{2}{N}\sum\limits_{i=1}^N e_i & \text{ for non-zero activation cases} \\
\end{cases} \\
& C(v) = CrossEntropy(v) & =
\begin{cases}
& -log(\hat y) & \text{if y = 1} \\
& -log(1- \hat y) & \text{if y = 0} \\
\end{cases} \\
\end{cases}
$$
</td></tr>
<tr><td align=left>
</td>
</tr>
</table>
<table border=1pt align="left">
  <th>layer</th>
  <th>forward</th>
  <th>chain rule</th>
  <th>calc</th>
  <th>derivative</th>
  <th>gradient</th>
  <tr>
    <td>input</td>
    <td>$$X_1$$</td>
    <td/>
    <td/>
    <td>$$\delta$$</td>
    <td>$$\nabla$$</td>
  </tr>
  <tr>
    <td>linear</td>
    <td>$$Y_1 = W_1 X_1 + B_1$$</td>
    <td>$$
      \frac{\partial C}{\partial W_1} = \frac{\partial C}{\partial Y_1} \frac{\partial Y_1}{\partial W_1} \\
      \frac{\partial C}{\partial B_1} = \frac{\partial C}{\partial Y_1} \frac{\partial Y_1}{\partial B_1}$$</td>
    <td>$$= dY_1 \cdot
      \begin{cases}
      X_1^T \\
      1 \\
      \end{cases}$$</td>
    <td>$$dX_1 = \frac{\partial C}{\partial Y_1} \frac{\partial Y_1}{\partial X_1} = dY_1 \cdot W_1^T$$</td>
    <td>$$
      W'_1 = W_1 - \eta \frac{\partial C}{\partial W_1} \\
      B'_1 = B_1 - \eta \frac{\partial C}{\partial B_1}$$</td>
  </tr>
  <tr>
    <td>sigmoid<p/>relu</td>
    <td>$$Y_2 =
      \begin{cases}
      \sigma(Y_1) \\
      max(0,Y_1) \\
      \end{cases}$$</td>
    <td>$$\frac{\partial C}{\partial Y_1} = (\frac{\partial C}{\partial Y_3} \frac{\partial Y_3}{\partial Y_2}) \frac{\partial Y_2}{\partial Y_1}$$</td>
    <td>$$= dY_2 \cdot
      \begin{cases}
      \sigma^{-1}(Y_1) \\
      max^{-1}(0,Y_1) \\
      \end{cases}$$</td>
    <td>$$dY_1 = dY_2 \cdot
      \begin{cases}
      Y_1 \cdot (1 - Y_1) \\
      Y_1 \gt 0 \text{ ? 1 : 0} \\
      \end{cases}$$</td>
    <td/>
  </tr>
  <tr>
    <td>linear</td>
    <td>$$Y_3 = W_2 Y_2 + B_2$$</td>
    <td>$$
      \frac{\partial C}{\partial W_2} = \frac{\partial C}{\partial Y_3} \frac{\partial Y_3}{\partial W_2} \\
      \frac{\partial C}{\partial B_2} = \frac{\partial C}{\partial Y_3} \frac{\partial Y_3}{\partial B_2}$$</td>
    <td>$$= dY_3 \cdot
      \begin{cases}
      Y_2^T \\
      1 \\
      \end{cases}$$</td>
    <td>$$dY_2 = \frac{\partial C}{\partial Y_3} \frac{\partial Y_3}{\partial Y_2} = dY_3 \cdot W_2^T$$</td>
    <td>$$
      W'_2 = W_2 - \eta \frac{\partial C}{\partial W_2} \\
      B'_2 = B_2 - \eta \frac{\partial C}{\partial B_2}$$</td>
  </tr>
  <tr>
    <td>sigmoid<p/>relu</td>
    <td>$$
      Y_4 = \begin{cases}
      \sigma(Y_3) \\
      max(0,Y_3) \\
      \end{cases}$$</td>
    <td>$$\frac{\partial C}{\partial Y_3} = \frac{\partial C}{\partial Y_4} \frac{\partial Y_4}{\partial Y_3}$$</td>
    <td>$$= dY_4 \cdot
      \begin{cases}
      \sigma^{-1}(Y_3) \\
      max^{-1}(0,Y_3) \\
      \end{cases}$$</td>
    <td>$$dY_3 = dY_4 \cdot
      \begin{cases}
      Y_3 \cdot (1 - Y_3) \\
      Y_3 \gt 0 \text{ ? 1 : 0} \\
      \end{cases}$$</td>
    <td/>
  </tr>
  <tr>
    <td>loss</td>
    <td>$$C =
      \begin{cases}
        MSE(Y_4, L) \\
        \begin{cases}
        softmax(Y_4) \\
        CE(Y_4, L) \\
        \end{cases} \\
      \end{cases}$$</td>
    <td>$$\frac{\partial C}{\partial Y_4}$$</td>
    <td>$$
      \begin{cases}
      \frac{\partial}{\partial y_i} \{\frac{1}{N}\sum_{i=1}^N(y_i - L_i)^2\} \\
        \begin{cases}
        y_i \cdot (\delta_{ij} - y_j) \text{ where } \delta_{ij} =
          \begin{cases}
          1 \text{ if } i = j \\
          0 \text{ if } i \ne j \\
          \end{cases} \\
        \frac{\partial}{\partial y_i} \{-\sum_{i=1}^N y_i \cdot log(L_i)\} \\
        \end{cases} \\
      \end{cases}
      $$</td>
    <td>$$
      dY_4 = \begin{cases}
      Y_4 - L \\
      Y_4 - L \\
      \end{cases}$$</td>
    <td/>
</table>


